{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b9524bd-c75a-4264-9da1-b0c37b33b4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import pytesseract\n",
    "from glob import glob\n",
    "import spacy\n",
    "import re\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94f2deed-9939-4701-9a08-aeb8d9d2720e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ner = spacy.load('./outputClean/model-best/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdab2d26-051e-4c6d-a521-d1f8eb73db6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(txt):\n",
    "    whitespace = string.whitespace\n",
    "    punctuation = \"!#$%&\\'()*+:;<=>?[\\\\]^`{|}~\"\n",
    "    tableWhitespace = str.maketrans('','',whitespace)\n",
    "    tablePunctuation = str.maketrans('','',punctuation)\n",
    "    text = str(txt)\n",
    "    #text = text.lower()\n",
    "    removewhitespace = text.translate(tableWhitespace)\n",
    "    removepunctuation = removewhitespace.translate(tablePunctuation)\n",
    "    \n",
    "    return str(removepunctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30482803-1e03-4665-92a2-639154f3bbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class groupgen():\n",
    "    def __init__(self):\n",
    "        self.id = 0\n",
    "        self.text = ''\n",
    "        \n",
    "    def getgroup(self,text):\n",
    "        if self.text == text:\n",
    "            return self.id\n",
    "        else:\n",
    "            self.id +=1\n",
    "            self.text = text\n",
    "            return self.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85edf1b2-a801-495b-9636-82362f23ff74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(text,label):\n",
    "    if label == 'PHONE':\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'\\D','',text)\n",
    "        \n",
    "    elif label == 'EMAIL':\n",
    "        text = text.lower()\n",
    "        allow_special_char = '@_.\\-'\n",
    "        text = re.sub(r'[^A-Za-z0-9{} ]'.format(allow_special_char),'',text)\n",
    "        \n",
    "    elif label == 'WEB':\n",
    "        text = text.lower()\n",
    "        allow_special_char = ':/.%#\\-'\n",
    "        text = re.sub(r'[^A-Za-z0-9{} ]'.format(allow_special_char),'',text)\n",
    "        \n",
    "    elif label in ('NAME', 'DES'):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^a-z ]','',text)\n",
    "        text = text.title()\n",
    "        \n",
    "    elif label == 'ORG':\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^a-z0-9 ]','',text)\n",
    "        text = text.title()\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ebe6b25-7ca5-4348-b35f-f3c7292c6608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thuan@gmail.com'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser('Thuan)*&^^@GMAIL.COM', 'EMAIL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c96b884-66cd-4cd5-8f86-37e8215e14e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_gen = groupgen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b532a68-851f-4560-87a8-3cc222ea291d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictions(image):\n",
    "    # extract data using Pytesseract \n",
    "    tessData = pytesseract.image_to_data(image)\n",
    "    # convert into dataframe\n",
    "    tessList = list(map(lambda x:x.split('\\t'), tessData.split('\\n')))\n",
    "    df = pd.DataFrame(tessList[1:],columns=tessList[0])\n",
    "    df.dropna(inplace=True) # drop missing values\n",
    "    df['text'] = df['text'].apply(cleanText)\n",
    "\n",
    "    # convet data into content\n",
    "    df_clean = df.query('text != \"\" ')\n",
    "    content = \" \".join([w for w in df_clean['text']])\n",
    "    print(content)\n",
    "    # get prediction from NER model\n",
    "    doc = model_ner(content)\n",
    "\n",
    "    # converting doc in json\n",
    "    docjson = doc.to_json()\n",
    "    doc_text = docjson['text']\n",
    "\n",
    "    # creating tokens\n",
    "    datafram_tokens = pd.DataFrame(docjson['tokens'])\n",
    "    datafram_tokens['token'] = datafram_tokens[['start','end']].apply(\n",
    "        lambda x:doc_text[x[0]:x[1]] , axis = 1)\n",
    "\n",
    "    right_table = pd.DataFrame(docjson['ents'])[['start','label']]\n",
    "    datafram_tokens = pd.merge(datafram_tokens,right_table,how='left',on='start')\n",
    "    datafram_tokens.fillna('O',inplace=True)\n",
    "\n",
    "    # join lable to df_clean dataframe\n",
    "    df_clean['end'] = df_clean['text'].apply(lambda x: len(x)+1).cumsum() - 1 \n",
    "    df_clean['start'] = df_clean[['text','end']].apply(lambda x: x[1] - len(x[0]),axis=1)\n",
    "\n",
    "    # inner join with start \n",
    "    dataframe_info = pd.merge(df_clean,datafram_tokens[['start','token','label']],how='inner',on='start')\n",
    "\n",
    "    # Bounding Box\n",
    "\n",
    "    bb_df = dataframe_info.query(\"label != 'O' \")\n",
    "\n",
    "    bb_df['label'] = bb_df['label'].apply(lambda x: x[2:])\n",
    "    bb_df['group'] = bb_df['label'].apply(grp_gen.getgroup)\n",
    "\n",
    "    # right and bottom of bounding box\n",
    "    bb_df[['left','top','width','height']] = bb_df[['left','top','width','height']].astype(int)\n",
    "    bb_df['right'] = bb_df['left'] + bb_df['width']\n",
    "    bb_df['bottom'] = bb_df['top'] + bb_df['height']\n",
    "\n",
    "    # tagging: groupby group\n",
    "    col_group = ['left','top','right','bottom','label','token','group']\n",
    "    group_tag_img = bb_df[col_group].groupby(by='group')\n",
    "    img_tagging = group_tag_img.agg({\n",
    "\n",
    "        'left':min,\n",
    "        'right':max,\n",
    "        'top':min,\n",
    "        'bottom':max,\n",
    "        'label':np.unique,\n",
    "        'token':lambda x: \" \".join(x)\n",
    "\n",
    "    })\n",
    "\n",
    "    img_bb = image.copy()\n",
    "    for l,r,t,b,label,token in img_tagging.values:\n",
    "        cv2.rectangle(img_bb,(l,t),(r,b),(0,255,0),2)\n",
    "\n",
    "        cv2.putText(img_bb,label,(l,t),cv2.FONT_HERSHEY_PLAIN,1,(255,0,255),2)\n",
    "\n",
    "\n",
    "    # Entities\n",
    "\n",
    "    info_array = dataframe_info[['token','label']].values\n",
    "    entities = dict(NAME=[],ORG=[],DES=[],PHONE=[],EMAIL=[],WEB=[])\n",
    "    previous = 'O'\n",
    "\n",
    "    for token, label in info_array:\n",
    "        bio_tag = label[0]\n",
    "        label_tag = label[2:]\n",
    "\n",
    "        # step -1 parse the token\n",
    "        text = parser(token,label_tag)\n",
    "\n",
    "        if bio_tag in ('B','I'):\n",
    "\n",
    "            if previous != label_tag:\n",
    "                entities[label_tag].append(text)\n",
    "\n",
    "            else:\n",
    "                if bio_tag == \"B\":\n",
    "                    entities[label_tag].append(text)\n",
    "\n",
    "                else:\n",
    "                    if label_tag in (\"NAME\",'ORG','DES'):\n",
    "                        entities[label_tag][-1] = entities[label_tag][-1] + \" \" + text\n",
    "\n",
    "                    else:\n",
    "                        entities[label_tag][-1] = entities[label_tag][-1] + text\n",
    "\n",
    "\n",
    "\n",
    "        previous = label_tag\n",
    "        \n",
    "    return img_bb, entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333b7bc7-5131-4cc1-b3d8-4ec88d675ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
